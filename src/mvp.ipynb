{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression: Banking Marketing Campaign"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle imports upfront\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 1.1. Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_url='https://raw.githubusercontent.com/4GeeksAcademy/logistic-regression-project-tutorial/main/bank-marketing-campaign-data.csv'\n",
    "data_df=pd.read_csv(data_url, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age        job  marital    education  default housing loan    contact  \\\n",
      "0   56  housemaid  married     basic.4y       no      no   no  telephone   \n",
      "1   57   services  married  high.school  unknown      no   no  telephone   \n",
      "2   37   services  married  high.school       no     yes   no  telephone   \n",
      "3   40     admin.  married     basic.6y       no      no   no  telephone   \n",
      "4   56   services  married  high.school       no      no  yes  telephone   \n",
      "\n",
      "  month day_of_week  ...  campaign  pdays  previous     poutcome emp.var.rate  \\\n",
      "0   may         mon  ...         1    999         0  nonexistent          1.1   \n",
      "1   may         mon  ...         1    999         0  nonexistent          1.1   \n",
      "2   may         mon  ...         1    999         0  nonexistent          1.1   \n",
      "3   may         mon  ...         1    999         0  nonexistent          1.1   \n",
      "4   may         mon  ...         1    999         0  nonexistent          1.1   \n",
      "\n",
      "   cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
      "0          93.994          -36.4      4.857       5191.0  no  \n",
      "1          93.994          -36.4      4.857       5191.0  no  \n",
      "2          93.994          -36.4      4.857       5191.0  no  \n",
      "3          93.994          -36.4      4.857       5191.0  no  \n",
      "4          93.994          -36.4      4.857       5191.0  no  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "               age      duration      campaign         pdays      previous  \\\n",
      "count  41188.00000  41188.000000  41188.000000  41188.000000  41188.000000   \n",
      "mean      40.02406    258.285010      2.567593    962.475454      0.172963   \n",
      "std       10.42125    259.279249      2.770014    186.910907      0.494901   \n",
      "min       17.00000      0.000000      1.000000      0.000000      0.000000   \n",
      "25%       32.00000    102.000000      1.000000    999.000000      0.000000   \n",
      "50%       38.00000    180.000000      2.000000    999.000000      0.000000   \n",
      "75%       47.00000    319.000000      3.000000    999.000000      0.000000   \n",
      "max       98.00000   4918.000000     56.000000    999.000000      7.000000   \n",
      "\n",
      "       emp.var.rate  cons.price.idx  cons.conf.idx     euribor3m   nr.employed  \n",
      "count  41188.000000    41188.000000   41188.000000  41188.000000  41188.000000  \n",
      "mean       0.081886       93.575664     -40.502600      3.621291   5167.035911  \n",
      "std        1.570960        0.578840       4.628198      1.734447     72.251528  \n",
      "min       -3.400000       92.201000     -50.800000      0.634000   4963.600000  \n",
      "25%       -1.800000       93.075000     -42.700000      1.344000   5099.100000  \n",
      "50%        1.100000       93.749000     -41.800000      4.857000   5191.000000  \n",
      "75%        1.400000       93.994000     -36.400000      4.961000   5228.100000  \n",
      "max        1.400000       94.767000     -26.900000      5.045000   5228.100000  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41188 entries, 0 to 41187\n",
      "Data columns (total 21 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   age             41188 non-null  int64  \n",
      " 1   job             41188 non-null  object \n",
      " 2   marital         41188 non-null  object \n",
      " 3   education       41188 non-null  object \n",
      " 4   default         41188 non-null  object \n",
      " 5   housing         41188 non-null  object \n",
      " 6   loan            41188 non-null  object \n",
      " 7   contact         41188 non-null  object \n",
      " 8   month           41188 non-null  object \n",
      " 9   day_of_week     41188 non-null  object \n",
      " 10  duration        41188 non-null  int64  \n",
      " 11  campaign        41188 non-null  int64  \n",
      " 12  pdays           41188 non-null  int64  \n",
      " 13  previous        41188 non-null  int64  \n",
      " 14  poutcome        41188 non-null  object \n",
      " 15  emp.var.rate    41188 non-null  float64\n",
      " 16  cons.price.idx  41188 non-null  float64\n",
      " 17  cons.conf.idx   41188 non-null  float64\n",
      " 18  euribor3m       41188 non-null  float64\n",
      " 19  nr.employed     41188 non-null  float64\n",
      " 20  y               41188 non-null  object \n",
      "dtypes: float64(5), int64(5), object(11)\n",
      "memory usage: 6.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Your code here....\n",
    "# Your code here....\n",
    "print(data_df.head())\n",
    "\n",
    "print(data_df.describe())\n",
    "\n",
    "print(data_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First separate the features from the labels\n",
    "labels=data_df['y']\n",
    "features=data_df.drop('y', axis=1)\n",
    "\n",
    "# Do the test-train split\n",
    "training_features, testing_features, training_labels, testing_labels=train_test_split(\n",
    "    features,\n",
    "    labels,\n",
    "    test_size=0.25, \n",
    "    random_state=315\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 30891 entries, 33905 to 29283\n",
      "Data columns (total 30 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   age                30891 non-null  int64  \n",
      " 1   marital            30891 non-null  object \n",
      " 2   education          30891 non-null  object \n",
      " 3   default            30891 non-null  object \n",
      " 4   housing            30891 non-null  object \n",
      " 5   loan               30891 non-null  object \n",
      " 6   contact            30891 non-null  object \n",
      " 7   month              30891 non-null  object \n",
      " 8   day_of_week        30891 non-null  object \n",
      " 9   duration           30891 non-null  int64  \n",
      " 10  campaign           30891 non-null  int64  \n",
      " 11  pdays              30891 non-null  int64  \n",
      " 12  previous           30891 non-null  int64  \n",
      " 13  poutcome           30891 non-null  object \n",
      " 14  emp.var.rate       30891 non-null  float64\n",
      " 15  cons.price.idx     30891 non-null  float64\n",
      " 16  cons.conf.idx      30891 non-null  float64\n",
      " 17  euribor3m          30891 non-null  float64\n",
      " 18  nr.employed        30891 non-null  float64\n",
      " 19  job_blue-collar    30891 non-null  int64  \n",
      " 20  job_entrepreneur   30891 non-null  int64  \n",
      " 21  job_housemaid      30891 non-null  int64  \n",
      " 22  job_management     30891 non-null  int64  \n",
      " 23  job_retired        30891 non-null  int64  \n",
      " 24  job_self-employed  30891 non-null  int64  \n",
      " 25  job_services       30891 non-null  int64  \n",
      " 26  job_student        30891 non-null  int64  \n",
      " 27  job_technician     30891 non-null  int64  \n",
      " 28  job_unemployed     30891 non-null  int64  \n",
      " 29  job_unknown        30891 non-null  int64  \n",
      "dtypes: float64(5), int64(16), object(9)\n",
      "memory usage: 7.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# Names of columns we want to encode\n",
    "encoded_columns=['job']\n",
    "\n",
    "# Do the encoding\n",
    "training_features=pd.get_dummies(training_features, columns=encoded_columns, dtype=int, drop_first=True)\n",
    "testing_features=pd.get_dummies(testing_features, columns=encoded_columns, dtype=int, drop_first=True)\n",
    "\n",
    "training_features.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age                    int64\n",
      "marital               object\n",
      "education             object\n",
      "default               object\n",
      "housing               object\n",
      "loan                  object\n",
      "contact               object\n",
      "month                 object\n",
      "day_of_week           object\n",
      "duration               int64\n",
      "campaign               int64\n",
      "pdays                  int64\n",
      "previous               int64\n",
      "poutcome              object\n",
      "emp.var.rate         float64\n",
      "cons.price.idx       float64\n",
      "cons.conf.idx        float64\n",
      "euribor3m            float64\n",
      "nr.employed          float64\n",
      "job_blue-collar        int64\n",
      "job_entrepreneur       int64\n",
      "job_housemaid          int64\n",
      "job_management         int64\n",
      "job_retired            int64\n",
      "job_self-employed      int64\n",
      "job_services           int64\n",
      "job_student            int64\n",
      "job_technician         int64\n",
      "job_unemployed         int64\n",
      "job_unknown            int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(training_features.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature: default\n",
      " no: 24400 (59.2%)\n",
      " unknown: 6488 (15.8%)\n",
      " yes: 3 (0.0%)\n",
      "\n",
      "Feature: housing\n",
      " yes: 16072 (39.0%)\n",
      " no: 14075 (34.2%)\n",
      " unknown: 744 (1.8%)\n",
      "\n",
      "Feature: loan\n",
      " no: 25468 (61.8%)\n",
      " yes: 4679 (11.4%)\n",
      " unknown: 744 (1.8%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def feature_composition(df: pd.DataFrame, features: list) -> None:\n",
    "    '''Takes a dataframe and a list of features. Prints out\n",
    "    the unique levels of that feature with their count and \n",
    "    percent.'''\n",
    "\n",
    "    for i, column_name in enumerate(features):\n",
    "        value_counts=df[column_name].value_counts().T.to_dict()\n",
    "\n",
    "        print(f'\\nFeature: {column_name}')\n",
    "\n",
    "        for key, value in value_counts.items():\n",
    "            percent_value=(value/len(data_df)) * 100\n",
    "            print(f' {key}: {value} ({percent_value:.1f}%)')\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "training_features['marital'] = label_encoder.fit_transform(training_features['marital'])\n",
    "\n",
    "training_features['education'] = label_encoder.fit_transform(training_features['education'])\n",
    "\n",
    "training_features['contact'] = label_encoder.fit_transform(training_features['contact'])\n",
    "\n",
    "feature_composition(training_features, ['default','housing','loan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 30891 entries, 33905 to 29283\n",
      "Data columns (total 35 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   age                30891 non-null  int64  \n",
      " 1   education          30891 non-null  int64  \n",
      " 2   month              30891 non-null  object \n",
      " 3   day_of_week        30891 non-null  object \n",
      " 4   duration           30891 non-null  int64  \n",
      " 5   campaign           30891 non-null  int64  \n",
      " 6   pdays              30891 non-null  int64  \n",
      " 7   previous           30891 non-null  int64  \n",
      " 8   poutcome           30891 non-null  object \n",
      " 9   emp.var.rate       30891 non-null  float64\n",
      " 10  cons.price.idx     30891 non-null  float64\n",
      " 11  cons.conf.idx      30891 non-null  float64\n",
      " 12  euribor3m          30891 non-null  float64\n",
      " 13  nr.employed        30891 non-null  float64\n",
      " 14  job_blue-collar    30891 non-null  int64  \n",
      " 15  job_entrepreneur   30891 non-null  int64  \n",
      " 16  job_housemaid      30891 non-null  int64  \n",
      " 17  job_management     30891 non-null  int64  \n",
      " 18  job_retired        30891 non-null  int64  \n",
      " 19  job_self-employed  30891 non-null  int64  \n",
      " 20  job_services       30891 non-null  int64  \n",
      " 21  job_student        30891 non-null  int64  \n",
      " 22  job_technician     30891 non-null  int64  \n",
      " 23  job_unemployed     30891 non-null  int64  \n",
      " 24  job_unknown        30891 non-null  int64  \n",
      " 25  marital_1          30891 non-null  int64  \n",
      " 26  marital_2          30891 non-null  int64  \n",
      " 27  marital_3          30891 non-null  int64  \n",
      " 28  default_unknown    30891 non-null  int64  \n",
      " 29  default_yes        30891 non-null  int64  \n",
      " 30  housing_unknown    30891 non-null  int64  \n",
      " 31  housing_yes        30891 non-null  int64  \n",
      " 32  loan_unknown       30891 non-null  int64  \n",
      " 33  loan_yes           30891 non-null  int64  \n",
      " 34  contact_1          30891 non-null  int64  \n",
      "dtypes: float64(5), int64(27), object(3)\n",
      "memory usage: 8.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# Names of columns we want to encode\n",
    "encoded_columns=['marital','default','housing','loan','contact']\n",
    "\n",
    "# Do the encoding\n",
    "training_features=pd.get_dummies(training_features, columns=encoded_columns, dtype=int, drop_first=True)\n",
    "testing_features=pd.get_dummies(testing_features, columns=encoded_columns, dtype=int, drop_first=True)\n",
    "\n",
    "training_features.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 30891 entries, 33905 to 29283\n",
      "Data columns (total 32 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   age                30891 non-null  int64  \n",
      " 1   education          30891 non-null  int64  \n",
      " 2   month              30891 non-null  object \n",
      " 3   day_of_week        30891 non-null  object \n",
      " 4   duration           30891 non-null  int64  \n",
      " 5   campaign           30891 non-null  int64  \n",
      " 6   emp.var.rate       30891 non-null  float64\n",
      " 7   cons.price.idx     30891 non-null  float64\n",
      " 8   cons.conf.idx      30891 non-null  float64\n",
      " 9   euribor3m          30891 non-null  float64\n",
      " 10  nr.employed        30891 non-null  float64\n",
      " 11  job_blue-collar    30891 non-null  int64  \n",
      " 12  job_entrepreneur   30891 non-null  int64  \n",
      " 13  job_housemaid      30891 non-null  int64  \n",
      " 14  job_management     30891 non-null  int64  \n",
      " 15  job_retired        30891 non-null  int64  \n",
      " 16  job_self-employed  30891 non-null  int64  \n",
      " 17  job_services       30891 non-null  int64  \n",
      " 18  job_student        30891 non-null  int64  \n",
      " 19  job_technician     30891 non-null  int64  \n",
      " 20  job_unemployed     30891 non-null  int64  \n",
      " 21  job_unknown        30891 non-null  int64  \n",
      " 22  marital_1          30891 non-null  int64  \n",
      " 23  marital_2          30891 non-null  int64  \n",
      " 24  marital_3          30891 non-null  int64  \n",
      " 25  default_unknown    30891 non-null  int64  \n",
      " 26  default_yes        30891 non-null  int64  \n",
      " 27  housing_unknown    30891 non-null  int64  \n",
      " 28  housing_yes        30891 non-null  int64  \n",
      " 29  loan_unknown       30891 non-null  int64  \n",
      " 30  loan_yes           30891 non-null  int64  \n",
      " 31  contact_1          30891 non-null  int64  \n",
      "dtypes: float64(5), int64(25), object(2)\n",
      "memory usage: 7.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# Names of columns to drop\n",
    "column_drops=['poutcome', 'pdays', 'previous']\n",
    "\n",
    "# Do the drops\n",
    "training_features.drop(column_drops, axis=1, inplace=True)\n",
    "\n",
    "# Do the same thing to the testing data\n",
    "testing_features.drop(column_drops, axis=1, inplace=True)\n",
    "\n",
    "# Take a look\n",
    "training_features.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. EDA\n",
    "\n",
    "### 2.1. Baseline model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a reusable helper function for cross-validation here. We are going to\n",
    "# be doing a lot of cross-validation, this allows us to reuse this code\n",
    "# without having to copy-paste it over and over.\n",
    "\n",
    "def cross_val(model, features: pd.DataFrame, labels: pd.Series) -> list[float]:\n",
    "    '''Reusable helper function to run cross-validation on a model. Takes model,\n",
    "    Pandas data frame of features and Pandas data series of labels. Returns \n",
    "    list of cross-validation fold accuracy scores as percents.'''\n",
    "\n",
    "    # Define the cross-validation strategy\n",
    "    cross_validation=StratifiedKFold(n_splits=7, shuffle=True, random_state=315)\n",
    "\n",
    "    # Run the cross-validation, collecting the scores\n",
    "    scores=cross_val_score(\n",
    "        model,\n",
    "        features,\n",
    "        labels,\n",
    "        cv=cross_validation,\n",
    "        n_jobs=-1,\n",
    "        scoring='accuracy'\n",
    "    )\n",
    "\n",
    "    # Print mean and standard deviation of the scores\n",
    "    print(f'Cross-validation accuracy: {(scores.mean() * 100):.2f} +/- {(scores.std() * 100):.2f}%')\n",
    "\n",
    "    # Return the scores\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature: day_of_week\n",
      " thu: 6479 (15.7%)\n",
      " mon: 6350 (15.4%)\n",
      " wed: 6089 (14.8%)\n",
      " tue: 6079 (14.8%)\n",
      " fri: 5894 (14.3%)\n",
      "\n",
      "Feature: month\n",
      " may: 10246 (24.9%)\n",
      " jul: 5334 (13.0%)\n",
      " aug: 4668 (11.3%)\n",
      " jun: 4047 (9.8%)\n",
      " nov: 3113 (7.6%)\n",
      " apr: 1965 (4.8%)\n",
      " oct: 541 (1.3%)\n",
      " sep: 434 (1.1%)\n",
      " mar: 402 (1.0%)\n",
      " dec: 141 (0.3%)\n"
     ]
    }
   ],
   "source": [
    "feature_composition(training_features, ['day_of_week'])\n",
    "\n",
    "feature_composition(training_features, ['month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Don't worry about downcasting FutureWarning\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "# Define a helper function here so we can encode the time\n",
    "# features the same way on the training and testing data\n",
    "# without copy-pasting the same code\n",
    "def encode_time_features(data_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    '''Takes a Pandas dataframe and uses cyclical sin/cos to encode\n",
    "    month and day features. Returns updated dataframe.'''\n",
    "\n",
    "    # First convert the features to numeric\n",
    "    dict={'mon' : 1, 'tue' : 2, 'wed': 3, 'thu' : 4, 'fri': 5}\n",
    "    data_df=data_df.replace(dict)\n",
    "\n",
    "    dict={'jan' : 1, 'feb' : 2, 'mar': 3, 'apr' : 4, 'may': 5, 'jun': 6, 'jul': 7, 'aug': 8, 'sep': 9, 'oct': 10, 'nov': 11, 'dec': 12}\n",
    "    data_df=data_df.replace(dict)\n",
    "\n",
    "    # And fix the dtypes\n",
    "    data_df['day_of_week']=data_df['day_of_week'].astype(int)\n",
    "    data_df['month']=data_df['month'].astype(int)\n",
    "\n",
    "    # Now encode the day and month with sin/cos components\n",
    "    data_df['day_sin'] = np.sin(2 * np.pi * data_df['day_of_week']/7.0)\n",
    "    data_df['day_cos'] = np.cos(2 * np.pi * data_df['day_of_week']/7.0)\n",
    "\n",
    "    data_df['month_sin'] = np.sin(2 * np.pi * data_df['month']/12.0)\n",
    "    data_df['month_cos'] = np.cos(2 * np.pi * data_df['month']/12.0)\n",
    "\n",
    "    # Drop the original string features\n",
    "    data_df.drop(['month', 'day_of_week'], axis=1, inplace=True)\n",
    "\n",
    "    return data_df\n",
    "\n",
    "training_features=encode_time_features(training_features)\n",
    "testing_features=encode_time_features(testing_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation accuracy: 90.60 +/- 0.39%\n"
     ]
    }
   ],
   "source": [
    "# Instantiate a random forest classifier model\n",
    "model=LogisticRegression(random_state=315)\n",
    "\n",
    "# Run the cross-validation\n",
    "scores=cross_val(model, training_features, training_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Missing and/or extreme values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41176, 21)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here...\n",
    "data_df.drop_duplicates(inplace=True)\n",
    "data_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value count for column - job\n",
      "job\n",
      "admin.           10419\n",
      "blue-collar       9253\n",
      "technician        6739\n",
      "services          3967\n",
      "management        2924\n",
      "retired           1718\n",
      "entrepreneur      1456\n",
      "self-employed     1421\n",
      "housemaid         1060\n",
      "unemployed        1014\n",
      "student            875\n",
      "unknown            330\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "\n",
      "Value count for column - marital\n",
      "marital\n",
      "married     24921\n",
      "single      11564\n",
      "divorced     4611\n",
      "unknown        80\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "\n",
      "Value count for column - education\n",
      "education\n",
      "university.degree      12164\n",
      "high.school             9512\n",
      "basic.9y                6045\n",
      "professional.course     5240\n",
      "basic.4y                4176\n",
      "basic.6y                2291\n",
      "unknown                 1730\n",
      "illiterate                18\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "\n",
      "Value count for column - default\n",
      "default\n",
      "no         32577\n",
      "unknown     8596\n",
      "yes            3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "\n",
      "Value count for column - housing\n",
      "housing\n",
      "yes        21571\n",
      "no         18615\n",
      "unknown      990\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "\n",
      "Value count for column - loan\n",
      "loan\n",
      "no         33938\n",
      "yes         6248\n",
      "unknown      990\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "\n",
      "Value count for column - contact\n",
      "contact\n",
      "cellular     26135\n",
      "telephone    15041\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "\n",
      "Value count for column - month\n",
      "month\n",
      "may    13767\n",
      "jul     7169\n",
      "aug     6176\n",
      "jun     5318\n",
      "nov     4100\n",
      "apr     2631\n",
      "oct      717\n",
      "sep      570\n",
      "mar      546\n",
      "dec      182\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "\n",
      "Value count for column - day_of_week\n",
      "day_of_week\n",
      "thu    8618\n",
      "mon    8512\n",
      "wed    8134\n",
      "tue    8086\n",
      "fri    7826\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "\n",
      "Value count for column - poutcome\n",
      "poutcome\n",
      "nonexistent    35551\n",
      "failure         4252\n",
      "success         1373\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "\n",
      "Value count for column - y\n",
      "y\n",
      "no     36537\n",
      "yes     4639\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Your code here...\n",
    "columns = ['job', 'marital','education', 'default', 'housing', 'loan', 'contact', 'month', 'day_of_week', 'poutcome', 'y']\n",
    "\n",
    "for column in columns:\n",
    "    print (f'Value count for column - {column}')\n",
    "    print(data_df[column].value_counts())\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit the scaler to the selected columns\n",
    "scaler.fit(data_df[['campaign','previous','emp.var.rate','cons.price.idx','cons.conf.idx','euribor3m','nr.employed']])\n",
    "\n",
    "# Transform the selected columns and assign the result back to those columns in the DataFrame\n",
    "data_df[['campaign','previous','emp.var.rate','cons.price.idx','cons.conf.idx','euribor3m','nr.employed']] = scaler.transform(data_df[['campaign','previous','emp.var.rate','cons.price.idx','cons.conf.idx','euribor3m','nr.employed']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.698753</td>\n",
       "      <td>0.60251</td>\n",
       "      <td>0.957379</td>\n",
       "      <td>0.859735</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.698753</td>\n",
       "      <td>0.60251</td>\n",
       "      <td>0.957379</td>\n",
       "      <td>0.859735</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.698753</td>\n",
       "      <td>0.60251</td>\n",
       "      <td>0.957379</td>\n",
       "      <td>0.859735</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.698753</td>\n",
       "      <td>0.60251</td>\n",
       "      <td>0.957379</td>\n",
       "      <td>0.859735</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.698753</td>\n",
       "      <td>0.60251</td>\n",
       "      <td>0.957379</td>\n",
       "      <td>0.859735</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41183</th>\n",
       "      <td>73</td>\n",
       "      <td>retired</td>\n",
       "      <td>married</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>nov</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>0.479167</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.089322</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41184</th>\n",
       "      <td>46</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>nov</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>0.479167</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.089322</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41185</th>\n",
       "      <td>56</td>\n",
       "      <td>retired</td>\n",
       "      <td>married</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>nov</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>0.479167</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.089322</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41186</th>\n",
       "      <td>44</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>nov</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>0.479167</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.089322</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41187</th>\n",
       "      <td>74</td>\n",
       "      <td>retired</td>\n",
       "      <td>married</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>nov</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>999</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>failure</td>\n",
       "      <td>0.479167</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.089322</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41176 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age          job  marital            education default housing loan  \\\n",
       "0       56    housemaid  married             basic.4y      no      no   no   \n",
       "1       57     services  married          high.school     NaN      no   no   \n",
       "2       37     services  married          high.school      no     yes   no   \n",
       "3       40       admin.  married             basic.6y      no      no   no   \n",
       "4       56     services  married          high.school      no      no  yes   \n",
       "...    ...          ...      ...                  ...     ...     ...  ...   \n",
       "41183   73      retired  married  professional.course      no     yes   no   \n",
       "41184   46  blue-collar  married  professional.course      no      no   no   \n",
       "41185   56      retired  married    university.degree      no     yes   no   \n",
       "41186   44   technician  married  professional.course      no      no   no   \n",
       "41187   74      retired  married  professional.course      no     yes   no   \n",
       "\n",
       "         contact month day_of_week  ...  campaign  pdays  previous  \\\n",
       "0      telephone   may         mon  ...  0.000000    999  0.000000   \n",
       "1      telephone   may         mon  ...  0.000000    999  0.000000   \n",
       "2      telephone   may         mon  ...  0.000000    999  0.000000   \n",
       "3      telephone   may         mon  ...  0.000000    999  0.000000   \n",
       "4      telephone   may         mon  ...  0.000000    999  0.000000   \n",
       "...          ...   ...         ...  ...       ...    ...       ...   \n",
       "41183   cellular   nov         fri  ...  0.000000    999  0.000000   \n",
       "41184   cellular   nov         fri  ...  0.000000    999  0.000000   \n",
       "41185   cellular   nov         fri  ...  0.018182    999  0.000000   \n",
       "41186   cellular   nov         fri  ...  0.000000    999  0.000000   \n",
       "41187   cellular   nov         fri  ...  0.036364    999  0.142857   \n",
       "\n",
       "          poutcome emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  \\\n",
       "0      nonexistent     0.937500        0.698753        0.60251   0.957379   \n",
       "1      nonexistent     0.937500        0.698753        0.60251   0.957379   \n",
       "2      nonexistent     0.937500        0.698753        0.60251   0.957379   \n",
       "3      nonexistent     0.937500        0.698753        0.60251   0.957379   \n",
       "4      nonexistent     0.937500        0.698753        0.60251   0.957379   \n",
       "...            ...          ...             ...            ...        ...   \n",
       "41183  nonexistent     0.479167        1.000000        0.00000   0.089322   \n",
       "41184  nonexistent     0.479167        1.000000        0.00000   0.089322   \n",
       "41185  nonexistent     0.479167        1.000000        0.00000   0.089322   \n",
       "41186  nonexistent     0.479167        1.000000        0.00000   0.089322   \n",
       "41187      failure     0.479167        1.000000        0.00000   0.089322   \n",
       "\n",
       "       nr.employed    y  \n",
       "0         0.859735   no  \n",
       "1         0.859735   no  \n",
       "2         0.859735   no  \n",
       "3         0.859735   no  \n",
       "4         0.859735   no  \n",
       "...            ...  ...  \n",
       "41183     0.000000  yes  \n",
       "41184     0.000000   no  \n",
       "41185     0.000000   no  \n",
       "41186     0.000000  yes  \n",
       "41187     0.000000   no  \n",
       "\n",
       "[41176 rows x 21 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = data_df.replace('unknown', np.nan)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in data_df.columns[data_df.dtypes == 'object']:\n",
    "    data_df[var] = data_df[var].fillna(data_df[var].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in data_df.columns[data_df.dtypes == 'int64']:\n",
    "    data_df[var] = data_df[var].fillna(data_df[var].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>41176.00000</td>\n",
       "      <td>41176.000000</td>\n",
       "      <td>41176.000000</td>\n",
       "      <td>41176.000000</td>\n",
       "      <td>41176.000000</td>\n",
       "      <td>41176.000000</td>\n",
       "      <td>41176.000000</td>\n",
       "      <td>41176.000000</td>\n",
       "      <td>41176.000000</td>\n",
       "      <td>41176.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>40.02380</td>\n",
       "      <td>258.315815</td>\n",
       "      <td>0.028507</td>\n",
       "      <td>962.464810</td>\n",
       "      <td>0.024716</td>\n",
       "      <td>0.725400</td>\n",
       "      <td>0.535744</td>\n",
       "      <td>0.430843</td>\n",
       "      <td>0.677237</td>\n",
       "      <td>0.769130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10.42068</td>\n",
       "      <td>259.305321</td>\n",
       "      <td>0.050369</td>\n",
       "      <td>186.937102</td>\n",
       "      <td>0.070709</td>\n",
       "      <td>0.327267</td>\n",
       "      <td>0.225580</td>\n",
       "      <td>0.193634</td>\n",
       "      <td>0.393207</td>\n",
       "      <td>0.273162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>32.00000</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.340608</td>\n",
       "      <td>0.338912</td>\n",
       "      <td>0.160961</td>\n",
       "      <td>0.512287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>38.00000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.603274</td>\n",
       "      <td>0.376569</td>\n",
       "      <td>0.957379</td>\n",
       "      <td>0.859735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>47.00000</td>\n",
       "      <td>319.000000</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.698753</td>\n",
       "      <td>0.602510</td>\n",
       "      <td>0.980957</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>98.00000</td>\n",
       "      <td>4918.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               age      duration      campaign         pdays      previous  \\\n",
       "count  41176.00000  41176.000000  41176.000000  41176.000000  41176.000000   \n",
       "mean      40.02380    258.315815      0.028507    962.464810      0.024716   \n",
       "std       10.42068    259.305321      0.050369    186.937102      0.070709   \n",
       "min       17.00000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%       32.00000    102.000000      0.000000    999.000000      0.000000   \n",
       "50%       38.00000    180.000000      0.018182    999.000000      0.000000   \n",
       "75%       47.00000    319.000000      0.036364    999.000000      0.000000   \n",
       "max       98.00000   4918.000000      1.000000    999.000000      1.000000   \n",
       "\n",
       "       emp.var.rate  cons.price.idx  cons.conf.idx     euribor3m   nr.employed  \n",
       "count  41176.000000    41176.000000   41176.000000  41176.000000  41176.000000  \n",
       "mean       0.725400        0.535744       0.430843      0.677237      0.769130  \n",
       "std        0.327267        0.225580       0.193634      0.393207      0.273162  \n",
       "min        0.000000        0.000000       0.000000      0.000000      0.000000  \n",
       "25%        0.333333        0.340608       0.338912      0.160961      0.512287  \n",
       "50%        0.937500        0.603274       0.376569      0.957379      0.859735  \n",
       "75%        1.000000        0.698753       0.602510      0.980957      1.000000  \n",
       "max        1.000000        1.000000       1.000000      1.000000      1.000000  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.get_dummies(data_df, columns=['y','job','marital','education','default','housing','loan','contact','month','day_of_week','poutcome'], drop_first=True)\n",
    "data_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Specifying the columns using strings is only supported for dataframes.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_indexing.py:341\u001b[0m, in \u001b[0;36m_get_column_indices\u001b[0;34m(X, key)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 341\u001b[0m     all_columns \u001b[38;5;241m=\u001b[39m \u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'columns'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[77], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m Pipeline(steps\u001b[38;5;241m=\u001b[39m[(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreprocessor\u001b[39m\u001b[38;5;124m'\u001b[39m, preprocessor)])\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Fit and transform the training features\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m training_features \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Only transform the testing features (no fitting)\u001b[39;00m\n\u001b[1;32m     31\u001b[0m testing_features \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mtransform(testing_features)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/pipeline.py:728\u001b[0m, in \u001b[0;36mPipeline.fit_transform\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    722\u001b[0m last_step_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_metadata_for_step(\n\u001b[1;32m    723\u001b[0m     step_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    724\u001b[0m     step_params\u001b[38;5;241m=\u001b[39mrouted_params[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]],\n\u001b[1;32m    725\u001b[0m     all_params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m    726\u001b[0m )\n\u001b[1;32m    727\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(last_step, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 728\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlast_step\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    729\u001b[0m \u001b[43m        \u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlast_step_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfit_transform\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    730\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m last_step\u001b[38;5;241m.\u001b[39mfit(Xt, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mlast_step_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mtransform(\n\u001b[1;32m    733\u001b[0m         Xt, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mlast_step_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransform\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    734\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_set_output.py:319\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 319\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    322\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    323\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    324\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    325\u001b[0m         )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py:992\u001b[0m, in \u001b[0;36mColumnTransformer.fit_transform\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_transformers()\n\u001b[1;32m    990\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(X)\n\u001b[0;32m--> 992\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_column_callables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    993\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_remainder(X)\n\u001b[1;32m    995\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _routing_enabled():\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py:551\u001b[0m, in \u001b[0;36mColumnTransformer._validate_column_callables\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    549\u001b[0m         columns \u001b[38;5;241m=\u001b[39m columns(X)\n\u001b[1;32m    550\u001b[0m     all_columns\u001b[38;5;241m.\u001b[39mappend(columns)\n\u001b[0;32m--> 551\u001b[0m     transformer_to_input_indices[name] \u001b[38;5;241m=\u001b[39m \u001b[43m_get_column_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_columns \u001b[38;5;241m=\u001b[39m all_columns\n\u001b[1;32m    554\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transformer_to_input_indices \u001b[38;5;241m=\u001b[39m transformer_to_input_indices\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_indexing.py:343\u001b[0m, in \u001b[0;36m_get_column_indices\u001b[0;34m(X, key)\u001b[0m\n\u001b[1;32m    341\u001b[0m     all_columns \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[0;32m--> 343\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    344\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpecifying the columns using strings is only supported for dataframes.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    345\u001b[0m     )\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    347\u001b[0m     columns \u001b[38;5;241m=\u001b[39m [key]\n",
      "\u001b[0;31mValueError\u001b[0m: Specifying the columns using strings is only supported for dataframes."
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Define which columns are categorical and which are numeric\n",
    "categorical_columns = ['marital', 'contact']  # Example: columns with categorical data\n",
    "numeric_columns = ['age', 'balance', 'duration']  # Example: columns with numeric data\n",
    "\n",
    "# Preprocessing pipeline for categorical columns: OneHotEncoding\n",
    "categorical_transformer = OneHotEncoder(drop='first', dtype=int, handle_unknown='ignore')\n",
    "\n",
    "# Preprocessing pipeline for numeric columns: StandardScaler\n",
    "numeric_transformer = StandardScaler()\n",
    "\n",
    "# Combine the transformers into a ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_columns),\n",
    "        ('cat', categorical_transformer, categorical_columns)\n",
    "    ],\n",
    "    remainder='passthrough'  # Keep other columns as they are (if any)\n",
    ")\n",
    "\n",
    "# Create a pipeline\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor)])\n",
    "\n",
    "# Fit and transform the training features\n",
    "training_features = pipeline.fit_transform(training_features)\n",
    "\n",
    "# Only transform the testing features (no fitting)\n",
    "testing_features = pipeline.transform(testing_features)\n",
    "\n",
    "# Check the shape of the resulting numpy arrays (after transformation)\n",
    "print(f'Training features are: {type(training_features)}')\n",
    "print(f'Training features shape: {training_features.shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'high.school'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_30447/3184444503.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Scale the features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mstandard_scaler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtraining_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstandard_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtesting_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstandard_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtesting_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Training features are: {type(training_features)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Training features shape: {training_features.shape}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m             return_tuple = (\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, copy)\u001b[0m\n\u001b[1;32m   1058\u001b[0m         \"\"\"\n\u001b[1;32m   1059\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m         \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1062\u001b[0;31m         X = validate_data(\n\u001b[0m\u001b[1;32m   1063\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1064\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m             \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2940\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2941\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2942\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2944\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2945\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2946\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2947\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1052\u001b[0m                         )\n\u001b[1;32m   1053\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m                 raise ValueError(\n\u001b[1;32m   1058\u001b[0m                     \u001b[0;34m\"Complex data not supported\\n{}\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m                 ) from complex_warning\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[1;32m    828\u001b[0m         \u001b[0;31m# Use NumPy API to support order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m         \u001b[0;31m# At this point array is a NumPy ndarray. We convert it to an array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m         \u001b[0;31m# container that is consistent with the input's namespace.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, dtype, copy)\u001b[0m\n\u001b[1;32m   2149\u001b[0m     def __array__(\n\u001b[1;32m   2150\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool_t\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2151\u001b[0m     ) -> np.ndarray:\n\u001b[1;32m   2152\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2153\u001b[0;31m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2154\u001b[0m         if (\n\u001b[1;32m   2155\u001b[0m             \u001b[0mastype_is_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2156\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0musing_copy_on_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'high.school'"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Scale the features\n",
    "standard_scaler=StandardScaler().fit(training_features)\n",
    "training_features=standard_scaler.transform(training_features)\n",
    "testing_features=standard_scaler.transform(testing_features)\n",
    "\n",
    "print(f'Training features are: {type(training_features)}')\n",
    "print(f'Training features shape: {training_features.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5. Label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last, encode the labels\n",
    "label_encoder=LabelEncoder().fit(training_labels)\n",
    "training_labels=label_encoder.transform(training_labels)\n",
    "testing_labels=label_encoder.transform(testing_labels)\n",
    "\n",
    "print(f'Training labels: {training_labels}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model optimization\n",
    "\n",
    "### 4.1. Model tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Cross-validation of optimized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Final model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
